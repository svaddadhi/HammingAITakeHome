This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-11-30T01:35:54.384Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
docs/
  DESIGN.md
src/
  analyzer/
    responseAnalyzer.ts
  call-manager/
    client.ts
  discovery/
    conversationTree.ts
  orchestrator/
    discoveryOrchestrator.ts
  transcription/
    transcriptionService.ts
  utils/
    logger.ts
    openai.ts
  visualization/
    progressVisualizer.ts
  webhook/
    index.ts
  index.ts
  server.ts
.gitignore
eslint.config.js
package.json
README.md
tsconfig.json

================================================================
Repository Files
================================================================

================
File: docs/DESIGN.md
================
I'll create a comprehensive design document for your voice agent discovery system. Let me break this down into clear, logical sections that will guide the implementation.

# Voice Agent Discovery System Design Document

## System Overview

The Voice Agent Discovery System is designed to automatically explore and map out the conversation paths possible with AI voice agents. It systematically places calls, processes responses, and builds a comprehensive map of the agent's capabilities through synthetic conversations. Think of it as an automated explorer that charts unknown conversational territory, similar to how a web crawler discovers and maps websites.

## Core Architecture

### Component Structure

The system is organized into several key modules that work together:

1. Discovery Orchestrator

   - Acts as the central brain of the system
   - Manages the overall discovery process
   - Maintains the state of exploration
   - Coordinates between other components
   - Implements backoff and retry strategies

2. Call Manager

   - Handles all interactions with the phone API endpoints
   - Manages rate limiting and concurrent calls
   - Implements retry logic for failed calls
   - Tracks call status and recordings

3. Conversation Analyzer

   - Processes audio recordings into text
   - Analyzes responses to identify new paths
   - Determines appropriate follow-up prompts
   - Identifies when a conversation branch is complete

4. State Manager

   - Tracks discovered conversation paths
   - Maintains the conversation tree structure
   - Identifies unexplored branches
   - Prevents redundant exploration

5. Progress Reporter
   - Provides real-time console updates
   - Generates visual representation of the discovery process
   - Logs important events and milestones
   - Creates final report of discovered paths

### Data Structures

The conversation tree structure is fundamental to this system. Each node represents a conversation state and contains:

```typescript
interface ConversationNode {
  id: string;
  prompt: string;
  response: string;
  children: ConversationNode[];
  status: "unexplored" | "in-progress" | "completed";
  metadata: {
    timestamp: Date;
    callId: string;
    depth: number;
    path: string[];
  };
}
```

## Process Flow

1. Initial Setup Phase

   - System configuration validation
   - API connectivity testing
   - Setting up webhook server
   - Initializing state management

2. Discovery Phase

   - Start with root-level prompts
   - Queue exploration tasks
   - Process responses
   - Identify new branches
   - Update conversation tree

3. Analysis Phase

   - Process audio recordings
   - Extract meaningful information
   - Identify conversation patterns
   - Detect terminal states

4. Documentation Phase
   - Generate visual representation
   - Create detailed path documentation
   - Export discovered scenarios

## Key Algorithms

### Path Discovery Algorithm

The system uses a modified breadth-first search approach to explore conversation paths:

1. Start with initial greeting
2. For each response:
   - Analyze content
   - Generate relevant follow-up prompts
   - Queue new exploration tasks
3. Track exploration depth
4. Implement cycle detection
5. Handle terminal states

### Response Analysis

Implements natural language processing to:

1. Categorize responses
2. Identify key information requests
3. Detect conversation state changes
4. Recognize completion signals

## Error Handling and Resilience

The system implements multiple layers of error handling:

1. Call-Level Resilience

   - Retry logic for failed calls
   - Exponential backoff strategy
   - Circuit breaker pattern for API calls

2. State-Level Resilience
   - Periodic state snapshots
   - Recovery mechanisms
   - Progress preservation

## Performance Considerations

1. Concurrency Management

   - Parallel call processing
   - Rate limiting compliance
   - Resource utilization control

2. Memory Management
   - Efficient tree structure
   - Periodic cleanup
   - Resource poolingI'll create a comprehensive design document for your voice agent discovery system. Let me break this down into clear, logical sections that will guide the implementation.

# Voice Agent Discovery System Design Document

## System Overview

The Voice Agent Discovery System is designed to automatically explore and map out the conversation paths possible with AI voice agents. It systematically places calls, processes responses, and builds a comprehensive map of the agent's capabilities through synthetic conversations. Think of it as an automated explorer that charts unknown conversational territory, similar to how a web crawler discovers and maps websites.

## Core Architecture

### Component Structure

The system is organized into several key modules that work together:

1. Discovery Orchestrator

   - Acts as the central brain of the system
   - Manages the overall discovery process
   - Maintains the state of exploration
   - Coordinates between other components
   - Implements backoff and retry strategies

2. Call Manager

   - Handles all interactions with the phone API endpoints
   - Manages rate limiting and concurrent calls
   - Implements retry logic for failed calls
   - Tracks call status and recordings

3. Conversation Analyzer

   - Processes audio recordings into text
   - Analyzes responses to identify new paths
   - Determines appropriate follow-up prompts
   - Identifies when a conversation branch is complete

4. State Manager

   - Tracks discovered conversation paths
   - Maintains the conversation tree structure
   - Identifies unexplored branches
   - Prevents redundant exploration

5. Progress Reporter
   - Provides real-time console updates
   - Generates visual representation of the discovery process
   - Logs important events and milestones
   - Creates final report of discovered paths

### Data Structures

The conversation tree structure is fundamental to this system. Each node represents a conversation state and contains:

```typescript
interface ConversationNode {
  id: string;
  prompt: string;
  response: string;
  children: ConversationNode[];
  status: "unexplored" | "in-progress" | "completed";
  metadata: {
    timestamp: Date;
    callId: string;
    depth: number;
    path: string[];
  };
}
```

## Process Flow

1. Initial Setup Phase

   - System configuration validation
   - API connectivity testing
   - Setting up webhook server
   - Initializing state management

2. Discovery Phase

   - Start with root-level prompts
   - Queue exploration tasks
   - Process responses
   - Identify new branches
   - Update conversation tree

3. Analysis Phase

   - Process audio recordings
   - Extract meaningful information
   - Identify conversation patterns
   - Detect terminal states

4. Documentation Phase
   - Generate visual representation
   - Create detailed path documentation
   - Export discovered scenarios

## Key Algorithms

### Path Discovery Algorithm

The system uses a modified breadth-first search approach to explore conversation paths:

1. Start with initial greeting
2. For each response:
   - Analyze content
   - Generate relevant follow-up prompts
   - Queue new exploration tasks
3. Track exploration depth
4. Implement cycle detection
5. Handle terminal states

### Response Analysis

Implements natural language processing to:

1. Categorize responses
2. Identify key information requests
3. Detect conversation state changes
4. Recognize completion signals

## Error Handling and Resilience

The system implements multiple layers of error handling:

1. Call-Level Resilience

   - Retry logic for failed calls
   - Exponential backoff strategy
   - Circuit breaker pattern for API calls

2. State-Level Resilience
   - Periodic state snapshots
   - Recovery mechanisms
   - Progress preservation

## Performance Considerations

1. Concurrency Management

   - Parallel call processing
   - Rate limiting compliance
   - Resource utilization control

2. Memory Management
   - Efficient tree structure
   - Periodic cleanup
   - Resource pooling

## Monitoring and Debugging

The system provides comprehensive monitoring through:

1. Real-time console updates
2. Progress visualization
3. Detailed logging
4. Performance metrics

## Extension Points

The system is designed to be extensible in several ways:

1. New Voice Agent Types

   - Pluggable agent type handlers
   - Custom response processors

2. Additional Analysis Capabilities

   - Custom analyzers
   - New metric collectors

3. Alternative Output Formats
   - Custom report generators
   - Different visualization options

## Implementation Guidelines

1. Code Organization

   - Clear module boundaries
   - Dependency injection
   - Interface-based design
   - Comprehensive documentation

2. Testing Strategy
   - Unit tests for core logic
   - Integration tests for API interaction
   - Mock services for development
   - Scenario-based testing

Would you like me to elaborate on any particular aspect of this design? I can provide more detailed information about specific components or discuss potential implementation challenges and their solutions.

## Monitoring and Debugging

The system provides comprehensive monitoring through:

1. Real-time console updates
2. Progress visualization
3. Detailed logging
4. Performance metrics

## Extension Points

The system is designed to be extensible in several ways:

1. New Voice Agent Types

   - Pluggable agent type handlers
   - Custom response processors

2. Additional Analysis Capabilities

   - Custom analyzers
   - New metric collectors

3. Alternative Output Formats
   - Custom report generators
   - Different visualization options

## Implementation Guidelines

1. Code Organization

   - Clear module boundaries
   - Dependency injection
   - Interface-based design
   - Comprehensive documentation

2. Testing Strategy
   - Unit tests for core logic
   - Integration tests for API interaction
   - Mock services for development
   - Scenario-based testing

================
File: src/analyzer/responseAnalyzer.ts
================
// src/analyzer/responseAnalyzer.ts

import logger from "../utils/logger.js";
import { generateResponses } from "../utils/openai.js";

interface AnalysisResult {
  identifiedPaths: string[];
  isTerminalState: boolean;
  confidence: number;
}

/**
 * ResponseAnalyzer handles the analysis of voice agent responses and generates
 * appropriate system prompts for exploring different conversation paths.
 * It adapts its analysis based on the detected business context and
 * conversation state.
 */
export class ResponseAnalyzer {
  // Tracks the type of business we're interacting with
  private businessContext: string = "";

  // Universal indicators for conversation end points
  private static readonly TERMINAL_INDICATORS = [
    "goodbye",
    "thank you for calling",
    "have a nice day",
    "is there anything else",
    "end of our call",
    "have a great",
    "bye",
  ];

  // Universal markers for when the agent is expecting a response
  private static readonly CONVERSATION_INDICATORS = [
    "would you like",
    "can i help",
    "how can i",
    "what would you",
    "are you looking",
    "would you prefer",
    "do you need",
    "may i",
    "let me",
    "i can",
    "we have",
    "we offer",
    "is there",
    "could you",
    "what type",
    "which option",
    "speaking",
    "how may i",
    "how can i assist",
  ];

  constructor() {
    this.businessContext = "";
  }

  /**
   * Analyzes a voice agent's response to identify potential conversation paths
   * and generates appropriate system prompts for exploration
   */
  public async analyzeResponse(response: string): Promise<AnalysisResult> {
    try {
      const normalizedResponse = response.toLowerCase();

      // Detect business type if not already set
      if (!this.businessContext) {
        this.businessContext = this.detectBusinessType(response);
        logger.info("Detected business type", {
          businessContext: this.businessContext,
          responsePreview: response.substring(0, 50),
        });
      }

      // Handle different types of responses
      let identifiedPaths: string[] = [];
      let isTerminalState = false;

      // For initial greeting, generate context-aware initial prompts
      if (this.isInitialGreeting(normalizedResponse)) {
        identifiedPaths = await this.generateInitialSystemPrompts();
        isTerminalState = false;
      } else {
        // For ongoing conversation, analyze response and generate follow-up prompts
        identifiedPaths = await this.generateFollowUpPrompts(response);
        isTerminalState = this.isTerminalState(
          normalizedResponse,
          identifiedPaths.length > 0
        );
      }

      const confidence = this.calculateConfidence(
        identifiedPaths,
        normalizedResponse
      );

      logger.info("Completed response analysis", {
        businessType: this.businessContext,
        pathsIdentified: identifiedPaths.length,
        isTerminal: isTerminalState,
        confidence,
        firstPath: identifiedPaths[0]?.substring(0, 30),
        responsePreview: response.substring(0, 50),
      });

      return {
        identifiedPaths,
        isTerminalState,
        confidence,
      };
    } catch (error) {
      logger.error("Error analyzing response", {
        error: error instanceof Error ? error.message : "Unknown error",
        response: response.substring(0, 100),
      });
      // Return safe default values on error
      return {
        identifiedPaths: [this.createDefaultSystemPrompt()],
        isTerminalState: false,
        confidence: 0.3,
      };
    }
  }

  /**
   * Detects the type of business from the response
   */
  private detectBusinessType(response: string): string {
    const normalizedResponse = response.toLowerCase();

    if (
      normalizedResponse.includes("air conditioning") ||
      normalizedResponse.includes("plumbing") ||
      normalizedResponse.includes("hvac") ||
      normalizedResponse.includes("heating")
    ) {
      return "hvac_plumbing";
    } else if (
      normalizedResponse.includes("auto") ||
      normalizedResponse.includes("car") ||
      normalizedResponse.includes("dealership") ||
      normalizedResponse.includes("vehicle")
    ) {
      return "auto_dealership";
    }

    return "general_business";
  }

  /**
   * Generates initial system prompts based on the detected business context
   */
  private async generateInitialSystemPrompts(): Promise<string[]> {
    const scenarios = this.getBusinessScenarios(this.businessContext);
    const prompts = scenarios.map((scenario) =>
      this.createSystemPrompt(scenario)
    );

    logger.info("Generated initial system prompts", {
      businessContext: this.businessContext,
      promptCount: prompts.length,
    });

    return prompts;
  }

  /**
   * Gets relevant business scenarios based on the business type
   */
  private getBusinessScenarios(businessType: string): string[] {
    switch (businessType) {
      case "hvac_plumbing":
        return [
          "AC not cooling - emergency service needed",
          "Schedule routine AC maintenance",
          "Leaking pipe emergency",
          "Water heater replacement quote",
          "New AC installation consultation",
        ];
      case "auto_dealership":
        return [
          "Interest in new vehicle purchase",
          "Used car availability check",
          "Schedule test drive",
          "Trade-in value inquiry",
          "Service department appointment",
        ];
      default:
        return ["General service inquiry"];
    }
  }

  /**
   * Creates a formatted system prompt for a specific scenario
   */
  private createSystemPrompt(scenario: string): string {
    return `You are a customer calling about ${scenario}.
When the agent answers:
1. Clearly state your needs related to ${scenario}
2. Answer any questions about your situation naturally
3. Show interest in scheduling service or getting more information
4. Be ready to provide basic contact information if asked
Your goal is to explore the complete service path for ${scenario}.`;
  }

  /**
   * Creates a default system prompt for error cases
   */
  private createDefaultSystemPrompt(): string {
    return `You are a customer calling to inquire about available services.
When the agent answers:
1. Ask about their main services
2. Show interest in learning more
3. Be ready to ask follow-up questions
Your goal is to understand what services they offer.`;
  }

  /**
   * Generates follow-up system prompts based on the agent's response
   */
  private async generateFollowUpPrompts(response: string): Promise<string[]> {
    const hasConversationCues = ResponseAnalyzer.CONVERSATION_INDICATORS.some(
      (indicator) => response.toLowerCase().includes(indicator)
    );

    const prompt = `Based on this ${this.businessContext} agent's response: "${response}"
Generate 3-4 different customer scenarios that would:
1. Directly engage with the options/questions presented
2. Explore different service paths
3. Represent realistic customer situations
Keep scenarios focused and specific.`;

    const scenarios = await generateResponses(prompt, {
      temperature: hasConversationCues ? 0.7 : 0.8,
      maxResponses: hasConversationCues ? 4 : 3,
    });

    return scenarios.map((scenario) => this.createSystemPrompt(scenario));
  }

  /**
   * Checks if the response is an initial greeting
   */
  private isInitialGreeting(response: string): boolean {
    return (
      response.includes("thank you for calling") ||
      response.includes("hello") ||
      response.includes("hi there") ||
      response.includes("speaking") ||
      response.includes("welcome to") ||
      (response.includes("this is") && response.includes("how can i help"))
    );
  }

  /**
   * Determines if the response indicates end of conversation
   */
  private isTerminalState(
    response: string,
    hasIdentifiedPaths: boolean
  ): boolean {
    if (hasIdentifiedPaths) {
      return false;
    }

    const hasTerminalIndicators = ResponseAnalyzer.TERMINAL_INDICATORS.some(
      (indicator) => response.includes(indicator)
    );

    const hasConversationCues = ResponseAnalyzer.CONVERSATION_INDICATORS.some(
      (indicator) => response.includes(indicator)
    );

    return hasTerminalIndicators && !hasConversationCues;
  }

  /**
   * Calculates confidence score for the analysis
   */
  private calculateConfidence(paths: string[], response: string): number {
    let confidence = Math.min(paths.length * 0.2, 0.8);

    if (this.businessContext !== "general_business") {
      confidence += 0.1;
    }

    if (
      ResponseAnalyzer.CONVERSATION_INDICATORS.some((indicator) =>
        response.includes(indicator)
      )
    ) {
      confidence += 0.1;
    }

    if (this.isInitialGreeting(response)) {
      confidence += 0.1;
    }

    return Math.min(confidence, 1.0);
  }
}

================
File: src/call-manager/client.ts
================
import axios, { AxiosResponse } from "axios";
import axiosRetry from "axios-retry";
import logger from "../utils/logger.js";

// Configure axios retry logic for resilient API calls
axiosRetry(axios, {
  retries: 3,
  retryDelay: axiosRetry.exponentialDelay,
  retryCondition: (error) => {
    return (
      axiosRetry.isNetworkOrIdempotentRequestError(error) ||
      (error.response?.status ?? 0) >= 500
    );
  },
});

interface CallResponse {
  id: string;
  status?: string;
}

/**
 * CallManager handles interactions with the voice agent API.
 * It manages initiating calls and retrieving recordings, with built-in
 * retry logic for resilient operation.
 */
export class CallManager {
  private baseUrl: string;
  private token: string;

  /**
   * Creates a new instance of CallManager
   * @param baseUrl - Base URL for the voice agent API
   * @param token - Authentication token for API access
   * @throws Error if required parameters are missing
   */
  constructor(baseUrl: string, token: string) {
    if (!baseUrl || !token) {
      throw new Error("baseUrl and token are required");
    }

    this.baseUrl = baseUrl;
    this.token = token;

    logger.info("CallManager initialized", {
      baseUrl,
      hasToken: !!token,
    });
  }

  /**
   * Initiates a call to the voice agent
   * @param phoneNumber - Target phone number to call
   * @param systemPrompt - System prompt that guides the voice agent's behavior
   * @param webhookUrl - URL for receiving call status updates
   * @returns Promise resolving to the call ID
   * @throws Error if the call fails to initiate
   */
  async startCall(
    phoneNumber: string,
    systemPrompt: string,
    webhookUrl: string
  ): Promise<string> {
    if (!phoneNumber || !systemPrompt || !webhookUrl) {
      const error = new Error("Required parameters missing");
      logger.error("Call initiation failed - parameter validation", {
        hasPhoneNumber: !!phoneNumber,
        hasPrompt: !!systemPrompt,
        hasWebhookUrl: !!webhookUrl,
        error: error.message,
      });
      throw error;
    }

    try {
      const response: AxiosResponse<CallResponse> = await axios.post(
        `${this.baseUrl}/start-call`,
        {
          phone_number: phoneNumber,
          prompt: systemPrompt,
          webhook_url: webhookUrl,
        },
        {
          headers: {
            Authorization: `Bearer ${this.token}`,
            "Content-Type": "application/json",
          },
          timeout: 10000, // 10 second timeout
        }
      );

      logger.info("Call initiated successfully", {
        callId: response.data.id,
        phoneNumber,
        responseStatus: response.status,
      });

      return response.data.id;
    } catch (error) {
      const errorMessage =
        error instanceof Error ? error.message : "Unknown error";
      logger.error("Failed to initiate call", {
        error: errorMessage,
        phoneNumber,
        axiosError: axios.isAxiosError(error)
          ? {
              status: error.response?.status,
              statusText: error.response?.statusText,
              data: error.response?.data,
            }
          : undefined,
      });

      throw new Error(
        `Failed to initiate call to ${phoneNumber}: ${errorMessage}`
      );
    }
  }

  /**
   * Retrieves the recording for a completed call
   * @param callId - ID of the call to retrieve
   * @returns Promise resolving to the recording buffer
   * @throws Error if the recording cannot be retrieved
   */
  async retrieveRecording(callId: string): Promise<Buffer> {
    try {
      logger.info("Retrieving recording", {
        callId,
        timestamp: new Date().toISOString(),
      });

      const response: AxiosResponse = await axios.get(
        `${this.baseUrl.replace(
          "/rest/exercise",
          ""
        )}/media/exercise?id=${callId}`,
        {
          responseType: "arraybuffer",
          headers: {
            Authorization: `Bearer ${this.token}`,
          },
          timeout: 15000, // 15 second timeout for retrieving recordings
        }
      );

      logger.info("Successfully retrieved recording", {
        callId,
        contentLength: response.data.length,
        contentType: response.headers["content-type"],
      });

      return Buffer.from(response.data);
    } catch (error) {
      const errorMessage =
        error instanceof Error ? error.message : "Unknown error";
      logger.error("Failed to retrieve recording", {
        error: errorMessage,
        callId,
        axiosError: axios.isAxiosError(error)
          ? {
              status: error.response?.status,
              statusText: error.response?.statusText,
            }
          : undefined,
      });

      throw new Error(`Failed to retrieve recording: ${errorMessage}`);
    }
  }
}

================
File: src/discovery/conversationTree.ts
================
// src/discovery/conversationTree.ts

import logger from "../utils/logger.js";

// We define the possible states a node can be in during exploration
enum NodeStatus {
  UNEXPLORED = "unexplored",
  IN_PROGRESS = "in-progress",
  COMPLETED = "completed",
  FAILED = "failed",
}

// We've simplified the node interface to focus on essential properties
interface CallNode {
  id: string;
  // The system prompt that was used to initiate this conversation path
  systemPrompt: string;
  // The transcribed response received from the agent
  responseReceived: string;
  // ID of the call associated with this node
  callId: string;
  status: NodeStatus;
  children: CallNode[];
  parentId: string | null;
  timestamp: Date;
  depth: number;
  // Potential paths identified for further exploration
  potentialPrompts?: string[];
  retryCount: number;
}

/**
 * ConversationTree manages the structure and traversal of our voice agent
 * conversation discovery process. It maintains a tree where each node represents
 * a specific interaction with the voice agent, tracking how different system
 * prompts lead to different conversation paths.
 */
export class ConversationTree {
  private nodes: Map<string, CallNode>;
  private rootNode: CallNode | null;
  private maxDepth: number;

  constructor(maxDepth: number = 10) {
    this.nodes = new Map();
    this.rootNode = null;
    this.maxDepth = maxDepth;
  }

  /**
   * Initializes the tree with a root node representing our first interaction
   */
  public initializeRoot(systemPrompt: string, callId: string): CallNode {
    if (this.rootNode) {
      throw new Error("Tree already initialized");
    }

    const rootNode: CallNode = {
      id: "root",
      systemPrompt,
      responseReceived: "",
      callId,
      status: NodeStatus.IN_PROGRESS,
      children: [],
      parentId: null,
      timestamp: new Date(),
      depth: 0,
      retryCount: 0,
    };

    this.rootNode = rootNode;
    this.nodes.set(rootNode.id, rootNode);

    logger.info("Conversation tree initialized with root node", {
      nodeId: rootNode.id,
      callId,
      systemPrompt: systemPrompt.substring(0, 50),
    });

    return rootNode;
  }

  /**
   * Adds a new conversation path to explore by creating a new node
   */
  public addNode(
    parentId: string,
    systemPrompt: string,
    callId: string
  ): CallNode {
    const parentNode = this.nodes.get(parentId);
    if (!parentNode) {
      throw new Error(`Parent node ${parentId} not found`);
    }

    if (parentNode.depth >= this.maxDepth) {
      throw new Error(`Maximum depth ${this.maxDepth} reached`);
    }

    const newNode: CallNode = {
      id: `node_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      systemPrompt,
      responseReceived: "",
      callId,
      status: NodeStatus.IN_PROGRESS,
      children: [],
      parentId,
      timestamp: new Date(),
      depth: parentNode.depth + 1,
      retryCount: 0,
    };

    parentNode.children.push(newNode);
    this.nodes.set(newNode.id, newNode);

    logger.info("Added new conversation path node", {
      nodeId: newNode.id,
      parentId,
      depth: newNode.depth,
      systemPromptPreview: systemPrompt.substring(0, 50),
    });

    return newNode;
  }

  /**
   * Updates a node with the response received from the voice agent
   */
  public updateNodeWithResponse(
    nodeId: string,
    response: string,
    potentialPrompts?: string[]
  ): void {
    const node = this.nodes.get(nodeId);
    if (!node) {
      throw new Error(`Node ${nodeId} not found`);
    }

    node.responseReceived = response;
    node.potentialPrompts = potentialPrompts;
    node.status = NodeStatus.COMPLETED;

    logger.info("Updated node with agent response", {
      nodeId,
      responsePreview: response.substring(0, 50),
      potentialPathsCount: potentialPrompts?.length ?? 0,
    });
  }

  /**
   * Updates the status of a conversation path
   */
  public updateNodeStatus(nodeId: string, status: NodeStatus): void {
    const node = this.nodes.get(nodeId);
    if (!node) {
      throw new Error(`Node ${nodeId} not found`);
    }

    node.status = status;
    logger.info("Updated conversation path status", {
      nodeId,
      status,
      depth: node.depth,
    });
  }

  /**
   * Finds all nodes that have unexplored potential conversation paths
   */
  public getNodesWithUnexploredPaths(): CallNode[] {
    return Array.from(this.nodes.values()).filter(
      (node) =>
        node.status === NodeStatus.COMPLETED &&
        node.potentialPrompts?.length > 0 &&
        node.depth < this.maxDepth
    );
  }

  /**
   * Gets the complete conversation history from root to a specific node
   */
  public getPathToNode(nodeId: string): CallNode[] {
    const path: CallNode[] = [];
    let currentNode = this.nodes.get(nodeId);

    while (currentNode) {
      path.unshift(currentNode);
      currentNode = currentNode.parentId
        ? this.nodes.get(currentNode.parentId) ?? undefined
        : undefined;
    }

    return path;
  }

  /**
   * Gets all nodes at a specific depth in our conversation exploration
   */
  public getNodesAtDepth(depth: number): CallNode[] {
    return Array.from(this.nodes.values()).filter(
      (node) => node.depth === depth
    );
  }

  /**
   * Provides a summary of our conversation exploration progress
   */
  public getTreeSummary() {
    const totalNodes = this.nodes.size;
    const completedNodes = Array.from(this.nodes.values()).filter(
      (node) => node.status === NodeStatus.COMPLETED
    ).length;
    const maxDepthReached = Math.max(
      ...Array.from(this.nodes.values()).map((node) => node.depth)
    );

    return {
      totalPaths: totalNodes,
      completedPaths: completedNodes,
      maxDepthReached,
      maxAllowedDepth: this.maxDepth,
    };
  }

  /**
   * Gets all explored conversation paths
   */
  public getAllNodes(): CallNode[] {
    return Array.from(this.nodes.values());
  }
}

================
File: src/orchestrator/discoveryOrchestrator.ts
================
// src/orchestrator/discoveryOrchestrator.ts

import logger from "../utils/logger.js";
import { CallManager } from "../call-manager/client.js";
import { ConversationTree } from "../discovery/conversationTree.js";
import { ResponseAnalyzer } from "../analyzer/responseAnalyzer.js";
import { ProgressVisualizer } from "../visualization/progressVisualizer.js";

interface DiscoveryConfig {
  maxDepth: number;
  maxConcurrentCalls: number;
  initialPrompt: string;
  phoneNumber: string;
  webhookUrl: string;
}

interface DiscoveryState {
  isRunning: boolean;
  activeCallCount: number;
  completedCallCount: number;
  failedCallCount: number;
  lastUpdateTimestamp: Date;
}

/**
 * DiscoveryOrchestrator manages the systematic exploration of voice agent capabilities.
 * It coordinates between different components to:
 * 1. Initiate conversations with different system prompts
 * 2. Process agent responses to identify new paths
 * 3. Build a comprehensive map of possible conversation flows
 * 4. Track exploration progress and manage concurrent calls
 */
export class DiscoveryOrchestrator {
  private readonly callManager: CallManager;
  private readonly conversationTree: ConversationTree;
  private readonly responseAnalyzer: ResponseAnalyzer;
  private readonly config: DiscoveryConfig;
  private state: DiscoveryState;
  private readonly visualizer: ProgressVisualizer;
  private readonly MAX_RETRY_ATTEMPTS = 3;

  constructor(callManager: CallManager, config: DiscoveryConfig) {
    this.callManager = callManager;
    this.config = config;
    this.conversationTree = new ConversationTree(config.maxDepth);
    this.responseAnalyzer = new ResponseAnalyzer();
    this.visualizer = new ProgressVisualizer();

    this.state = {
      isRunning: false,
      activeCallCount: 0,
      completedCallCount: 0,
      failedCallCount: 0,
      lastUpdateTimestamp: new Date(),
    };
  }

  /**
   * Begins the discovery process by initiating the first conversation
   * with an initial system prompt. This starts our exploration of the
   * voice agent's capabilities.
   */
  public async startDiscovery(): Promise<void> {
    if (this.state.isRunning) {
      throw new Error("Discovery process is already running");
    }

    try {
      logger.info("Starting voice agent discovery process", {
        phoneNumber: this.config.phoneNumber,
        maxDepth: this.config.maxDepth,
        maxConcurrentCalls: this.config.maxConcurrentCalls,
      });

      this.state.isRunning = true;
      this.state.lastUpdateTimestamp = new Date();

      // Start with initial conversation
      const initialSystemPrompt = this.createInitialSystemPrompt();
      const callId = await this.callManager.startCall(
        this.config.phoneNumber,
        initialSystemPrompt,
        this.config.webhookUrl
      );

      // Initialize our conversation tree with this first interaction
      this.conversationTree.initializeRoot(initialSystemPrompt, callId);
      this.state.activeCallCount++;

      logger.info("Initial conversation started", {
        callId,
        systemPromptPreview: initialSystemPrompt.substring(0, 50),
      });
    } catch (error) {
      this.state.isRunning = false;
      logger.error("Failed to start discovery process", {
        error: error instanceof Error ? error.message : "Unknown error",
      });
      throw error;
    }
  }

  /**
   * Creates the initial system prompt that starts our discovery process.
   * This prompt is designed to elicit information about available services.
   */
  private createInitialSystemPrompt(): string {
    return `You are a customer making your first call to this business.
When the agent answers:
1. Express general interest in learning about their services
2. Be ready to ask follow-up questions about specific services
3. Show interest but avoid committing to any service yet
Your goal is to understand what services they offer and how they handle initial inquiries.`;
  }

  /**
   * Processes a completed call by analyzing the response and planning
   * the next conversations to explore.
   */
  public async handleCallCompleted(
    callId: string,
    response: string
  ): Promise<void> {
    try {
      const node = this.findNodeByCallId(callId);
      if (!node) {
        throw new Error(`No conversation node found for call ${callId}`);
      }

      // Analyze the response to identify new conversation paths to explore
      const analysis = await this.responseAnalyzer.analyzeResponse(response);
      this.conversationTree.updateNodeWithResponse(
        node.id,
        response,
        analysis.identifiedPaths
      );

      // Update discovery state
      this.state.activeCallCount--;
      this.state.completedCallCount++;
      this.state.lastUpdateTimestamp = new Date();

      // Visualize our progress
      this.visualizer.visualizeTree(this.conversationTree);
      this.visualizer.visualizeProgress(this.state);
      this.visualizer.logConversationEvent(node.id, "Conversation Completed", {
        responsePreview: response.substring(0, 100),
        newPathsIdentified: analysis.identifiedPaths.length,
      });

      // Continue exploration with newly discovered paths
      if (!analysis.isTerminalState) {
        await this.exploreNextPaths();
      }

      logger.info("Successfully processed completed conversation", {
        callId,
        nodeId: node.id,
        newPathsIdentified: analysis.identifiedPaths.length,
        isTerminal: analysis.isTerminalState,
      });
    } catch (error) {
      logger.error("Error processing completed conversation", {
        error: error instanceof Error ? error.message : "Unknown error",
        callId,
      });
      this.state.failedCallCount++;
    }
  }

  /**
   * Finds the conversation node associated with a specific call
   */
  private findNodeByCallId(callId: string) {
    return this.conversationTree
      .getAllNodes()
      .find((node) => node.callId === callId);
  }

  /**
   * Explores the next set of conversation paths based on our discoveries.
   * This method manages the concurrent exploration of different paths while
   * staying within our configured limits.
   */
  private async exploreNextPaths(): Promise<void> {
    if (!this.state.isRunning) return;

    try {
      const unexploredNodes =
        this.conversationTree.getNodesWithUnexploredPaths();

      for (const node of unexploredNodes) {
        if (this.state.activeCallCount >= this.config.maxConcurrentCalls) {
          logger.info("Reached maximum concurrent conversations", {
            activeCount: this.state.activeCallCount,
            maximum: this.config.maxConcurrentCalls,
          });
          break;
        }

        const nextPrompt = node.potentialPrompts?.[0];
        if (!nextPrompt) continue;

        // Remove this prompt from our queue since we're about to use it
        node.potentialPrompts = node.potentialPrompts?.slice(1);

        try {
          // Start a new conversation with this prompt
          const callId = await this.callManager.startCall(
            this.config.phoneNumber,
            nextPrompt,
            this.config.webhookUrl
          );

          // Add this new conversation path to our tree
          const newNode = this.conversationTree.addNode(
            node.id,
            nextPrompt,
            callId
          );

          this.state.activeCallCount++;
          this.state.lastUpdateTimestamp = new Date();

          // Update visualization
          this.visualizer.visualizeTree(this.conversationTree);
          this.visualizer.visualizeProgress(this.state);

          logger.info("Started exploration of new conversation path", {
            parentNodeId: node.id,
            newNodeId: newNode.id,
            callId,
            promptPreview: nextPrompt.substring(0, 50),
          });

          // Small delay between calls to avoid overwhelming the system
          await new Promise((resolve) => setTimeout(resolve, 500));
        } catch (error) {
          logger.error("Failed to explore conversation path", {
            error: error instanceof Error ? error.message : "Unknown error",
            parentNodeId: node.id,
            promptPreview: nextPrompt.substring(0, 50),
          });

          // Return the prompt to the queue for potential retry
          if (node.potentialPrompts) {
            node.potentialPrompts.push(nextPrompt);
          } else {
            node.potentialPrompts = [nextPrompt];
          }
        }
      }

      logger.info("Completed exploration cycle", {
        activeConversations: this.state.activeCallCount,
        completedConversations: this.state.completedCallCount,
        remainingUnexplored: unexploredNodes.length,
      });
    } catch (error) {
      logger.error("Error in path exploration process", {
        error: error instanceof Error ? error.message : "Unknown error",
        activeCallCount: this.state.activeCallCount,
      });
    }
  }

  /**
   * Handles failed calls by implementing retry logic up to a maximum
   * number of attempts.
   */
  public async handleCallFailed(callId: string): Promise<void> {
    try {
      const node = this.findNodeByCallId(callId);

      if (node) {
        const retryCount = node.retryCount || 0;
        if (retryCount < this.MAX_RETRY_ATTEMPTS) {
          logger.info("Retrying failed conversation", {
            callId,
            retryAttempt: retryCount + 1,
          });

          const newCallId = await this.callManager.startCall(
            this.config.phoneNumber,
            node.systemPrompt,
            this.config.webhookUrl
          );

          node.callId = newCallId;
          node.retryCount = retryCount + 1;
        } else {
          logger.warn("Maximum retry attempts reached", {
            callId,
            maxAttempts: this.MAX_RETRY_ATTEMPTS,
          });
          this.state.failedCallCount++;
        }
      }

      this.state.activeCallCount--;
      this.state.lastUpdateTimestamp = new Date();
    } catch (error) {
      logger.error("Error handling failed call", {
        error: error instanceof Error ? error.message : "Unknown error",
        callId,
      });
    }
  }

  /**
   * Gets the current state of the discovery process including
   * progress metrics and tree summary.
   */
  public getDiscoveryState() {
    return {
      ...this.state,
      treeSummary: this.conversationTree.getTreeSummary(),
    };
  }

  /**
   * Stops the discovery process gracefully.
   */
  public stopDiscovery(): void {
    this.state.isRunning = false;
    logger.info("Discovery process stopped", this.getDiscoveryState());
  }
}

================
File: src/transcription/transcriptionService.ts
================
// src/transcription/transcriptionService.ts

import { createClient } from "@deepgram/sdk";
import logger from "../utils/logger.js";

// This interface defines the structure of our transcription results
interface TranscriptionResult {
  text: string; // The transcribed text
  confidence: number; // How confident Deepgram is in the transcription
}

/**
 * TranscriptionService handles the conversion of voice agent recordings to text.
 * It uses Deepgram's AI-powered speech recognition to accurately transcribe
 * conversations, enabling us to analyze the agent's responses and identify
 * new conversation paths to explore.
 *
 * The service is configured to handle English language conversations with
 * specific optimizations for customer service interactions, including:
 * - Smart formatting for numbers, dates, and currency
 * - Punctuation for better readability
 * - Speaker diarization to distinguish between speakers
 */
export class TranscriptionService {
  private deepgramClient;

  /**
   * Creates a new instance of TranscriptionService
   * @param apiKey - Authentication key for Deepgram's API
   * @throws Error if the API key is not provided
   */
  constructor(apiKey: string) {
    if (!apiKey) {
      throw new Error("Deepgram API key is required for transcription");
    }

    this.deepgramClient = createClient(apiKey);
    logger.info("TranscriptionService initialized with Deepgram client");
  }

  /**
   * Transcribes an audio recording from a buffer
   * This method is used when we have the complete audio data in memory
   *
   * @param audioBuffer - The audio data to transcribe
   * @returns A promise containing the transcribed text and confidence score
   * @throws Error if transcription fails
   */
  async transcribeAudio(audioBuffer: Buffer): Promise<TranscriptionResult> {
    try {
      // Log the start of transcription with the audio size for debugging
      logger.info("Starting audio transcription", {
        bufferSize: audioBuffer.length,
        timestamp: new Date().toISOString(),
      });

      // Configure Deepgram with optimal settings for customer service calls
      const { result, error } =
        await this.deepgramClient.listen.prerecorded.transcribeFile(
          audioBuffer,
          {
            // Nova-2 model provides better accuracy for conversation transcription
            model: "nova-2",
            // Enable smart formatting for numbers and dates
            smart_format: true,
            // Disable utterance splits as we want complete sentences
            utterance_split: false,
            // Add punctuation for better readability
            punctuate: true,
            // Enable speaker identification
            diarize: true,
            // Convert numbers to digits
            numerals: true,
            // Specify language for better accuracy
            language: "en-US",
          }
        );

      if (error) {
        throw error;
      }

      // Extract the primary transcript and its confidence score
      const transcript =
        result.results?.channels[0]?.alternatives[0]?.transcript;
      const confidence =
        result.results?.channels[0]?.alternatives[0]?.confidence;

      if (!transcript) {
        throw new Error("No transcript received from Deepgram");
      }

      // Log successful transcription with quality metrics
      logger.info("Successfully transcribed audio", {
        confidenceScore: confidence,
        transcriptLength: transcript.length,
        transcriptPreview: transcript.substring(0, 50),
        timestamp: new Date().toISOString(),
      });

      return {
        text: transcript,
        confidence: confidence || 0,
      };
    } catch (error) {
      // Log detailed error information for debugging
      logger.error("Failed to transcribe audio", {
        error: error instanceof Error ? error.message : "Unknown error",
        errorType:
          error instanceof Error ? error.constructor.name : typeof error,
        timestamp: new Date().toISOString(),
      });

      throw new Error(
        `Transcription failed: ${
          error instanceof Error ? error.message : "Unknown error"
        }`
      );
    }
  }

  /**
   * Transcribes audio from a URL
   * This method is used when the audio is hosted remotely
   *
   * @param audioUrl - URL of the audio file to transcribe
   * @returns A promise containing the transcribed text and confidence score
   * @throws Error if transcription fails
   */
  async transcribeUrl(audioUrl: string): Promise<TranscriptionResult> {
    try {
      logger.info("Starting URL audio transcription", {
        url: audioUrl,
        timestamp: new Date().toISOString(),
      });

      const { result, error } =
        await this.deepgramClient.listen.prerecorded.transcribeUrl(
          {
            url: audioUrl,
          },
          {
            // Use same high-quality settings as file transcription
            model: "nova-2",
            smart_format: true,
          }
        );

      if (error) {
        throw error;
      }

      const transcript =
        result.results?.channels[0]?.alternatives[0]?.transcript;
      const confidence =
        result.results?.channels[0]?.alternatives[0]?.confidence;

      if (!transcript) {
        throw new Error("No transcript received from Deepgram");
      }

      logger.info("Successfully transcribed URL audio", {
        url: audioUrl,
        confidenceScore: confidence,
        transcriptLength: transcript.length,
        transcriptPreview: transcript.substring(0, 50),
        timestamp: new Date().toISOString(),
      });

      return {
        text: transcript,
        confidence: confidence || 0,
      };
    } catch (error) {
      logger.error("Failed to transcribe URL audio", {
        error: error instanceof Error ? error.message : "Unknown error",
        url: audioUrl,
        timestamp: new Date().toISOString(),
      });

      throw new Error(
        `URL transcription failed: ${
          error instanceof Error ? error.message : "Unknown error"
        }`
      );
    }
  }
}

================
File: src/utils/logger.ts
================
import winston from "winston";

const logger = winston.createLogger({
  level: "info",
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    // Write all logs with importance level of 'info' or less to combined.log
    new winston.transports.File({ filename: "logs/combined.log" }),
    // Write all logs with importance level of 'error' or less to error.log
    new winston.transports.File({ filename: "logs/error.log", level: "error" }),
    // Write to console during development
    new winston.transports.Console({
      format: winston.format.combine(
        winston.format.colorize(),
        winston.format.simple()
      ),
    }),
  ],
});

export default logger;

================
File: src/utils/openai.ts
================
// src/utils/openai.ts

import OpenAI from "openai";
import logger from "./logger.js";

// Initialize OpenAI client with environment variable
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

/**
 * Generates contextual responses for a given prompt using GPT-3.5-turbo
 * Enhanced with better error handling and response validation
 */
export async function generateResponses(
  prompt: string,
  options: {
    temperature?: number;
    maxResponses?: number;
    businessContext?: string;
  } = {}
): Promise<string[]> {
  const { temperature = 0.7, maxResponses = 4 } = options;

  try {
    // Create a more structured prompt for better response generation
    const enhancedPrompt = `As an AI testing voice response systems, analyze this interaction:

"${prompt}"

Generate ${maxResponses} different, natural customer responses for this situation.
Focus on responses that would:
1. Move the conversation forward
2. Be common in real customer service calls
3. Encourage the agent to provide more information or services

Format: Return ONLY the responses, one per line. Each response should be a complete statement.
Example format:
I need help with my AC, it's not cooling properly
I'd like to schedule a maintenance appointment
What services do you offer for plumbing issues?

Your responses:`;

    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        {
          role: "system",
          content:
            "You are an AI helping test customer service voice systems. Generate realistic customer responses that help explore all possible conversation paths. Keep responses natural and focused on common customer inquiries.",
        },
        { role: "user", content: enhancedPrompt },
      ],
      temperature: temperature,
      max_tokens: 300,
      presence_penalty: 0.6, // Encourage diverse responses
      frequency_penalty: 0.4, // Reduce repetition
    });

    // Process and clean up the responses
    const responses =
      completion.choices[0].message.content
        ?.split("\n")
        .map((line) => line.trim())
        .filter((line) => line.length > 0 && !line.startsWith("-"))
        .slice(0, maxResponses) ?? [];

    // Validate that we got meaningful responses
    if (responses.length === 0) {
      logger.warn("No responses generated from OpenAI", {
        prompt: prompt.substring(0, 100),
        rawResponse: completion.choices[0].message.content,
      });
      // Provide fallback responses for initial greeting
      if (prompt.toLowerCase().includes("thank you for calling")) {
        return [
          "I need help with a service issue",
          "I'd like to learn about your services",
          "I'm interested in scheduling an appointment",
          "Can you tell me about your rates?",
        ];
      }
    }

    logger.info("Successfully generated AI responses", {
      promptLength: prompt.length,
      responseCount: responses.length,
      firstResponse: responses[0]?.substring(0, 30),
    });

    return responses;
  } catch (error) {
    logger.error("Error generating AI responses", {
      error: error instanceof Error ? error.message : "Unknown error",
      promptPreview: prompt.substring(0, 100),
    });

    // Return fallback responses rather than empty array
    return [
      "I need some help with a service",
      "Could you tell me about your services?",
      "I'm interested in getting more information",
    ];
  }
}

================
File: src/visualization/progressVisualizer.ts
================
// src/visualization/progressVisualizer.ts

import { ConversationTree } from "../discovery/conversationTree.js";
import logger from "../utils/logger.js";
import chalk from "chalk";

interface VisualizationNode {
  id: string;
  systemPrompt: string; // Changed from 'prompt' to 'systemPrompt' for clarity
  response: string;
  status: string;
  depth: number;
  children: VisualizationNode[];
}

/**
 * ProgressVisualizer creates real-time visualizations of our voice agent discovery process.
 * It provides clear, formatted console output showing:
 * - The current conversation tree structure
 * - Active and completed conversation paths
 * - Success rates and exploration metrics
 * - Important events and milestones
 */
export class ProgressVisualizer {
  // Characters used to draw the tree structure in the console
  private static readonly TREE_CHARS = {
    vertical: "│",
    horizontal: "──",
    corner: "└",
    junction: "├",
    bullet: "●",
  };

  // Color coding for different conversation states
  private static readonly STATUS_COLORS = {
    unexplored: chalk.gray,
    "in-progress": chalk.yellow,
    completed: chalk.green,
    failed: chalk.red,
  };

  private static readonly PROMPT_DISPLAY_LENGTH = Number.MAX_SAFE_INTEGER; // Increased from 60
  private static readonly RESPONSE_DISPLAY_LENGTH = Number.MAX_SAFE_INTEGER;

  /**
   * Creates a visual representation of the current conversation tree.
   * This helps us understand how different conversation paths are related
   * and which areas have been explored.
   */
  public visualizeTree(tree: ConversationTree): void {
    // Clear console for fresh visualization
    console.clear();

    // Get the root node and prepare for visualization
    const nodes = tree.getAllNodes();
    const rootNode = nodes.find((node) => node.parentId === null);

    if (!rootNode) {
      logger.warn("No conversation data to visualize");
      return;
    }

    // Print header with current timestamp
    console.log(chalk.bold("\n=== Voice Agent Discovery Progress ==="));
    console.log(chalk.dim(`Time: ${new Date().toLocaleString()}\n`));

    // Convert the tree data for visualization
    const visualTree = this.convertToVisualNode(rootNode, nodes);

    // Render the tree structure
    this.renderNode(visualTree, "", true);

    // Print summary statistics
    this.printTreeSummary(tree);
  }

  /**
   * Shows the current progress of our discovery process, including
   * active conversations and success metrics.
   */
  public visualizeProgress(state: any): void {
    console.log(chalk.bold("\n=== Discovery Metrics ==="));

    // Active conversations
    console.log(chalk.yellow(`Active Conversations: ${state.activeCallCount}`));

    // Success metrics
    console.log(
      chalk.green(`Successfully Completed: ${state.completedCallCount}`)
    );

    // Failed attempts
    console.log(chalk.red(`Failed Attempts: ${state.failedCallCount}`));

    // Calculate and show success rate
    const totalAttempts = state.completedCallCount + state.failedCallCount;
    const successRate =
      totalAttempts > 0
        ? ((state.completedCallCount / totalAttempts) * 100).toFixed(1)
        : 0;
    console.log(chalk.blue(`Success Rate: ${successRate}%`));

    // Time tracking
    console.log(
      chalk.dim(`Last Update: ${state.lastUpdateTimestamp.toLocaleString()}`)
    );

    console.log(chalk.dim("=====================================\n"));
  }

  /**
   * Logs significant events during the discovery process with detailed context.
   * This helps track important milestones and debug issues.
   */
  public logConversationEvent(
    nodeId: string,
    event: string,
    details: any
  ): void {
    const timestamp = new Date().toISOString();
    const eventColor = this.getEventColor(event);

    console.log(eventColor(`\n[${timestamp}] ${event.toUpperCase()}`));
    console.log(chalk.dim(`Node: ${nodeId}`));

    // Format details for better readability
    Object.entries(details).forEach(([key, value]) => {
      if (typeof value === "string") {
        console.log(
          chalk.dim(`${key}: `) +
            this.truncateText(
              value as string,
              ProgressVisualizer.RESPONSE_DISPLAY_LENGTH
            )
        );
      } else {
        console.log(chalk.dim(`${key}: `) + value);
      }
    });

    console.log(chalk.dim("---"));
  }

  /**
   * Converts our conversation tree data into a format suitable for visualization.
   */
  private convertToVisualNode(node: any, allNodes: any[]): VisualizationNode {
    const children = allNodes.filter((n) => n.parentId === node.id);
    return {
      id: node.id,
      systemPrompt: node.systemPrompt,
      response: node.responseReceived,
      status: node.status,
      depth: node.depth,
      children: children.map((child) =>
        this.convertToVisualNode(child, allNodes)
      ),
    };
  }

  /**
   * Renders a node in the tree visualization with appropriate formatting and colors.
   */
  private renderNode(
    node: VisualizationNode,
    prefix: string,
    isLast: boolean
  ): void {
    const connector = isLast
      ? ProgressVisualizer.TREE_CHARS.corner
      : ProgressVisualizer.TREE_CHARS.junction;

    // Color the node based on its status
    const statusColor =
      ProgressVisualizer.STATUS_COLORS[
        node.status as keyof typeof ProgressVisualizer.STATUS_COLORS
      ] || chalk.white;

    // Render the node with its system prompt
    console.log(
      `${prefix}${connector}${ProgressVisualizer.TREE_CHARS.horizontal}` +
        statusColor(
          `[${node.status}] ${this.truncateText(
            node.systemPrompt,
            ProgressVisualizer.PROMPT_DISPLAY_LENGTH
          )}`
        )
    );

    // Show the response if available
    if (node.response) {
      console.log(
        `${prefix}${isLast ? " " : ProgressVisualizer.TREE_CHARS.vertical}   ` +
          chalk.dim(
            `Response: "${this.truncateText(
              node.response,
              ProgressVisualizer.RESPONSE_DISPLAY_LENGTH
            )}"`
          )
      );
    }

    // Render child nodes
    const childPrefix =
      prefix +
      (isLast ? "    " : ProgressVisualizer.TREE_CHARS.vertical + "   ");
    node.children.forEach((child, index) => {
      this.renderNode(child, childPrefix, index === node.children.length - 1);
    });
  }

  /**
   * Prints summary statistics about our discovery progress.
   */
  private printTreeSummary(tree: ConversationTree): void {
    const summary = tree.getTreeSummary();

    console.log(chalk.bold("\n=== Discovery Summary ==="));
    console.log(chalk.blue(`Total Conversation Paths: ${summary.totalPaths}`));
    console.log(chalk.green(`Completed Paths: ${summary.completedPaths}`));
    console.log(
      chalk.yellow(
        `Current Depth: ${summary.maxDepthReached}/${summary.maxAllowedDepth}`
      )
    );

    // Calculate and show completion percentage
    const completionRate = (
      (summary.completedPaths / summary.totalPaths) *
      100
    ).toFixed(1);
    console.log(chalk.cyan(`Completion Rate: ${completionRate}%`));

    console.log(chalk.dim("======================\n"));
  }

  /**
   * Gets the appropriate color for different event types.
   */
  private getEventColor(event: string): chalk.ChalkFunction {
    switch (event.toLowerCase()) {
      case "conversation completed":
        return chalk.green;
      case "conversation failed":
        return chalk.red;
      case "new path discovered":
        return chalk.blue;
      default:
        return chalk.white;
    }
  }

  /**
   * Truncates text to a specified length while preserving readability.
   */
  private truncateText(text: string, maxLength: number): string {
    return text.length > maxLength
      ? `${text.substring(0, maxLength - 3)}...`
      : text;
  }
}

================
File: src/webhook/index.ts
================
// src/webhook/index.ts

import { Router, Request, Response } from "express";
import { CallManager } from "../call-manager/client.js";
import { DiscoveryOrchestrator } from "../orchestrator/discoveryOrchestrator.js";
import { TranscriptionService } from "../transcription/transcriptionService.js";
import logger from "../utils/logger.js";

// Define the structure of incoming webhook payloads from the voice agent API
interface WebhookPayload {
  id: string;
  status:
    | "initiated" // Call has started
    | "in-progress" // Call is ongoing
    | "completed" // Call has finished successfully
    | "failed" // Call failed
    | "event_phone_call_connected" // Phone connection established
    | "event_phone_call_ended" // Phone call ended
    | "event_recording"; // Recording is available
  recording_available: boolean;
}

/**
 * WebhookHandler manages incoming notifications about our voice agent calls.
 * It serves as the coordination point between the voice agent API and our
 * discovery system, processing call events and managing the flow of conversation
 * recordings through our analysis pipeline.
 */
export class WebhookHandler {
  private router: Router;
  private callManager: CallManager;
  private orchestrator: DiscoveryOrchestrator;
  private transcriptionService: TranscriptionService;

  constructor(
    callManager: CallManager,
    orchestrator: DiscoveryOrchestrator,
    transcriptionService: TranscriptionService
  ) {
    this.router = Router();
    this.callManager = callManager;
    this.orchestrator = orchestrator;
    this.transcriptionService = transcriptionService;
    this.configureRoutes();
  }

  /**
   * Sets up the webhook endpoint that receives call status updates
   */
  private configureRoutes(): void {
    this.router.post("/callback", this.handleWebhook.bind(this));
  }

  /**
   * Processes incoming webhook notifications from the voice agent API
   */
  private async handleWebhook(req: Request, res: Response): Promise<void> {
    try {
      logger.info("Received webhook notification", {
        body: req.body,
        headers: req.headers,
        timestamp: new Date().toISOString(),
      });

      const payload = this.validatePayload(req.body);

      logger.info("Processing voice agent event", {
        callId: payload.id,
        status: payload.status,
        hasRecording: payload.recording_available,
      });

      // Process the webhook based on the call status
      await this.processWebhook(payload);

      // Send immediate acknowledgment to prevent retries
      res.status(200).json({ received: true });
    } catch (error) {
      logger.error("Error processing webhook", {
        error: error instanceof Error ? error.message : "Unknown error",
        body: req.body,
      });

      res.status(400).json({
        error: error instanceof Error ? error.message : "Unknown error",
      });
    }
  }

  /**
   * Validates the structure of incoming webhook payloads
   */
  private validatePayload(body: any): WebhookPayload {
    if (!body?.id || !body?.status) {
      throw new Error("Invalid webhook payload: missing required fields");
    }

    const validStatuses = [
      "initiated",
      "in-progress",
      "completed",
      "failed",
      "event_phone_call_connected",
      "event_phone_call_ended",
      "event_recording",
    ];

    if (!validStatuses.includes(body.status)) {
      throw new Error(`Invalid status: ${body.status}`);
    }

    return body as WebhookPayload;
  }

  /**
   * Routes webhook events to appropriate handlers based on call status
   */
  private async processWebhook(payload: WebhookPayload): Promise<void> {
    switch (payload.status) {
      case "completed":
      case "event_recording":
        if (payload.recording_available) {
          await this.handleRecordingAvailable(payload.id);
        } else {
          logger.warn("Call completed but recording not available", {
            callId: payload.id,
          });
        }
        break;

      case "failed":
        await this.orchestrator.handleCallFailed(payload.id);
        break;

      case "initiated":
      case "in-progress":
      case "event_phone_call_connected":
      case "event_phone_call_ended":
        logger.info("Call status update received", {
          callId: payload.id,
          status: payload.status,
        });
        break;

      default:
        logger.warn("Unhandled call status received", {
          callId: payload.id,
          status: payload.status,
        });
        break;
    }
  }

  /**
   * Processes available recordings by transcribing them and updating our discovery state
   */
  private async handleRecordingAvailable(callId: string): Promise<void> {
    try {
      logger.info("Processing available recording", { callId });

      // Retrieve the recording
      const recordingBuffer = await this.callManager.retrieveRecording(callId);

      // Transcribe the recording
      const transcriptionResult =
        await this.transcriptionService.transcribeAudio(recordingBuffer);

      logger.info("Successfully transcribed recording", {
        callId,
        confidence: transcriptionResult.confidence,
        transcriptLength: transcriptionResult.text.length,
      });

      // Pass the transcribed conversation to our orchestrator for analysis
      await this.orchestrator.handleCallCompleted(
        callId,
        transcriptionResult.text
      );
    } catch (error) {
      logger.error("Failed to process recording", {
        error: error instanceof Error ? error.message : "Unknown error",
        callId,
      });

      // Notify orchestrator of failure so it can retry if needed
      await this.orchestrator.handleCallFailed(callId);
    }
  }

  /**
   * Returns the configured router for use in the Express application
   */
  public getRouter(): Router {
    return this.router;
  }
}

================
File: src/index.ts
================
// src/index.ts

import "dotenv/config.js";
import Server from "./server.js";
import { CallManager } from "./call-manager/client.js";
import { WebhookHandler } from "./webhook/index.js";
import { DiscoveryOrchestrator } from "./orchestrator/discoveryOrchestrator.js";
import { TranscriptionService } from "./transcription/transcriptionService.js";
import logger from "./utils/logger.js";

// This function ensures all required environment variables are present
function validateEnvironmentVariables() {
  const required = [
    "BASE_URL", // Voice agent API base URL
    "API_TOKEN", // Authentication token for the API
    "DEEPGRAM_API_KEY", // API key for transcription service
    "TARGET_PHONE_NUMBER", // Phone number to call
    "WEBHOOK_URL", // URL for receiving call status updates
  ];

  const missing = required.filter((key) => !process.env[key]);
  if (missing.length > 0) {
    throw new Error(
      `Missing required environment variables: ${missing.join(", ")}`
    );
  }
}

// This function initializes and starts our discovery system
async function startServer() {
  validateEnvironmentVariables();

  try {
    // Initialize our core services with appropriate configuration
    const transcriptionService = new TranscriptionService(
      process.env.DEEPGRAM_API_KEY!
    );

    const callManager = new CallManager(
      process.env.BASE_URL!,
      process.env.API_TOKEN!
    );

    // Configure the discovery orchestrator with our exploration parameters
    const orchestrator = new DiscoveryOrchestrator(callManager, {
      maxDepth: 5, // Maximum conversation depth to explore
      maxConcurrentCalls: 3, // Maximum parallel conversations
      initialPrompt:
        "You are a customer calling to learn about available services. When the agent answers, ask about their main service offerings and show interest in learning more details.",
      phoneNumber: process.env.TARGET_PHONE_NUMBER!,
      webhookUrl: `${process.env.WEBHOOK_URL}/webhook/callback`,
    });

    // Set up the webhook handler to process call status updates
    const webhookHandler = new WebhookHandler(
      callManager,
      orchestrator,
      transcriptionService
    );

    // Initialize and start the server
    const server = new Server(Number(process.env.PORT) || 3000);
    server.addRoute("/webhook", webhookHandler.getRouter());
    await server.start();

    // Begin the discovery process
    await orchestrator.startDiscovery();

    logger.info("Voice agent discovery system started successfully", {
      targetPhone: process.env.TARGET_PHONE_NUMBER,
      webhookUrl: process.env.WEBHOOK_URL,
    });
  } catch (error) {
    logger.error("Failed to start voice agent discovery system", {
      error: error instanceof Error ? error.message : "Unknown error",
    });
    process.exit(1);
  }
}

// Start the system
startServer();

================
File: src/server.ts
================
// src/server.ts

import express, { Express, Request, Response, NextFunction } from "express";
import cors from "cors";
import helmet from "helmet";
import logger from "./utils/logger.js";

interface AppError extends Error {
  status?: number;
}

/**
 * Server class provides the HTTP server functionality for our discovery system.
 * It handles incoming webhook requests and provides appropriate security measures.
 */
class Server {
  private app: Express;
  private port: number;

  constructor(port: number = 3000) {
    this.app = express();
    this.port = port;
    this.configureMiddleware();
  }

  /**
   * Configures Express middleware for security and request handling
   */
  private configureMiddleware(): void {
    // Parse JSON request bodies
    this.app.use(express.json());

    // Configure CORS for security
    this.app.use(
      cors({
        origin: process.env.ALLOWED_ORIGINS?.split(",") || "*",
        methods: ["POST", "GET", "OPTIONS"],
        allowedHeaders: ["Content-Type", "Authorization"],
      })
    );

    // Add security headers
    this.app.use(helmet());

    // Log incoming requests
    this.app.use((req: Request, res: Response, next: NextFunction) => {
      logger.info("Incoming request", {
        method: req.method,
        path: req.path,
        ip: req.ip,
        timestamp: new Date().toISOString(),
      });
      next();
    });
  }

  /**
   * Configures error handling middleware
   */
  private configureErrorHandling(): void {
    // Handle 404 errors
    this.app.use((req: Request, res: Response, next: NextFunction) => {
      const error: AppError = new Error("Not Found");
      error.status = 404;
      next(error);
    });

    // Handle all other errors
    this.app.use(
      (error: AppError, req: Request, res: Response, next: NextFunction) => {
        logger.error("Server error", {
          error: error.message,
          stack: error.stack,
          path: req.path,
          method: req.method,
          timestamp: new Date().toISOString(),
        });

        res.status(error.status || 500).json({
          error: {
            message: error.message || "Internal server error",
            status: error.status || 500,
          },
        });
      }
    );
  }

  /**
   * Adds a new route handler to the server
   */
  public addRoute(path: string, router: express.Router): void {
    logger.info(`Adding route handler`, {
      path,
      timestamp: new Date().toISOString(),
    });

    // Add request logging for this route
    this.app.use(path, (req, res, next) => {
      logger.info(`Request received at ${path}`, {
        method: req.method,
        originalUrl: req.originalUrl,
        timestamp: new Date().toISOString(),
      });
      next();
    });

    this.app.use(path, router);
  }

  /**
   * Starts the server listening for requests
   */
  public async start(): Promise<void> {
    // Add error handling after all routes are configured
    this.configureErrorHandling();

    try {
      await new Promise<void>((resolve) => {
        this.app.listen(this.port, () => {
          logger.info("Server started", {
            port: this.port,
            timestamp: new Date().toISOString(),
          });
          resolve();
        });
      });
    } catch (error) {
      logger.error("Failed to start server", {
        error: error instanceof Error ? error.message : "Unknown error",
        port: this.port,
        timestamp: new Date().toISOString(),
      });
      throw error;
    }
  }
}

export default Server;

================
File: .gitignore
================
node_modules/
.env

================
File: eslint.config.js
================
import globals from "globals";
import pluginJs from "@eslint/js";
import tseslint from "typescript-eslint";


/** @type {import('eslint').Linter.Config[]} */
export default [
  {files: ["**/*.{js,mjs,cjs,ts}"]},
  {languageOptions: { globals: globals.browser }},
  pluginJs.configs.recommended,
  ...tseslint.configs.recommended,
];

================
File: package.json
================
{
  "name": "hammingaitakehome",
  "version": "1.0.0",
  "description": "",
  "main": "index.js",
  "type": "module",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "build": "tsc",
    "start": "tsx src/index.ts",
    "dev": "tsx watch src/index.ts"
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "devDependencies": {
    "@eslint/js": "^9.15.0",
    "@types/cors": "^2.8.17",
    "@types/express": "^5.0.0",
    "@types/node": "^22.10.1",
    "eslint": "^9.15.0",
    "globals": "^15.12.0",
    "ts-node": "^10.9.2",
    "ts-node-dev": "^2.0.0",
    "tsx": "^4.19.2",
    "typescript": "^5.7.2",
    "typescript-eslint": "^8.16.0"
  },
  "dependencies": {
    "@deepgram/sdk": "^3.9.0",
    "axios": "^1.7.8",
    "axios-retry": "^4.5.0",
    "chalk": "^5.3.0",
    "cors": "^2.8.5",
    "dotenv": "^16.4.5",
    "express": "^4.21.1",
    "helmet": "^8.0.0",
    "openai": "^4.73.1",
    "winston": "^3.17.0"
  }
}

================
File: README.md
================
# HammingAITakeHome

================
File: tsconfig.json
================
{
    "compilerOptions": {
      "target": "ES2022",
      "module": "NodeNext",
      "moduleResolution": "NodeNext",
      "outDir": "./dist",
      "rootDir": "./src",
      "strict": true,
      "esModuleInterop": true,
      "skipLibCheck": true,
      "forceConsistentCasingInFileNames": true,
      "allowJs": true,
      "resolveJsonModule": true
    },
    "include": ["src/**/*"],
    "exclude": ["node_modules"]
  }
